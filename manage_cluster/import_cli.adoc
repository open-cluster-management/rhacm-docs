[#importing-a-managed-cluster-with-the-cli]
= Importing a managed cluster with the CLI

After you install Red Hat Advanced Cluster Management for Kubernetes, you are ready to import a cluster to manage.
You can import from both the console and the CLI.
Follow this procedure to import from the CLI.

* <<cli_prerequisites,Prerequisites>>
* <<supported-architecture,Supported architecture>>
* <<importing-the-multicluster-endpoint,Importing the multicluster-endpoint>>

NOTE: A hub cluster cannot manage another hub cluster.

[#cli_prerequisites]
== Prerequisites

* You need a Red Hat Advanced Cluster Management for Kubernetes hub cluster that is deployed.
If you are importing bare metal clusters, you must have the hub cluster installed on Red Hat OpenShift Container Platform version 4.4, or later.
* You need a separate cluster that you want to manage and Internet connectivity.
* You need the Red Hat OpenShift Container Platform CLI version 4.3, or later, to run `oc` commands.
See https://docs.openshift.com/container-platform/4.3/cli_reference/openshift_cli/getting-started-cli.html[Getting started with the CLI] for information about installing and configuring the Red Hat OpenShift CLI, `oc`.
* You need to install the Kubernetes CLI, `kubectl`.
To install `kubectl`, see _Install and Set Up kubectl_ in the https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-macos[Kubernetes documentation].
+
NOTE: Download the installation file for CLI tools from the console.

[#supported-architecture]
== Supported architecture

* Linux
* macOS

[#prepare-for-import]
== Prepare for import

. Log in to your _hub cluster_.
Run the following command:
+
----
oc login
----

. Run the following command on the hub cluster to create the namespace.
*Note:* The cluster name that is defined in `<cluster_name>` is also used as the cluster namespace in the `.yaml` file file and commands:
+
----
oc new-project ${CLUSTER_NAME}
----

. If you are importing a Kubernetes cluster that is not a Red Hat OpenShift Container Platform cluster, run the following command to create a secret:
+
----
oc create -n ${CLUSTER_NAME} secret docker-registry quay-secret --docker-server=registry.redhat.io --docker-username=${DOCKER_USER} --docker-password=${DOCKER_PASS}
----
+
IMPORTANT: The command contains pull secret information that is copied to each of the imported clusters.
Anyone who can access the imported clusters can also view the pull secret information.
Consider creating a secondary pull secret at https://cloud.redhat.com/ or by creating a service account so your personal credentials are not compromised.
See https://docs.openshift.com/container-platform/4.4/openshift_images/managing_images/using-image-pull-secrets.html[Using image pull secrets] or https://docs.openshift.com/container-platform/4.4/authentication/understanding-and-creating-service-accounts.html[Understanding and creating service accounts] for more information.

. Edit the example ClusterRegistry cluster with the following sample of YAML:
+
----
apiVersion: clusterregistry.k8s.io/v1alpha1
kind: Cluster
metadata:
  labels:
    cloud: auto-detect
    name: <cluster_name>
    vendor: auto-detect
  name: <cluster_name>
  namespace: <cluster_name>
spec: {}
----

. Save the file as `cluster-registry.yaml`.
. Apply the with YAML file the following command:
+
----
oc apply -f cluster-registry.yaml
----

. Create the endpoint configuration file.
Enter the following example YAML:
+
----
apiVersion: multicloud.ibm.com/v1alpha1
kind: EndpointConfig
metadata:
  name: <cluster_name>
  namespace: <cluster_name>
spec:
  applicationManager:
    enabled: true
  clusterLabels:
    cloud: auto-detect
    vendor: auto-detect
  clusterName: <cluster_name>
  clusterNamespace: <cluster_name>
  connectionManager:
    enabledGlobalView: false
  imageRegistry: quay.io/open-cluster-management
  imagePullSecret: quay-secret
  policyController:
    enabled: true
  searchCollector:
    enabled: true
  serviceRegistry:
    enabled: true
  certPolicyController:
    enabled: true
    enabled: false
  iamPolicyController:
    enabled: true
  version: 2.0
----

. Save the file as `endpoint-config.yaml`.
. Apply the YAML.
Run the following command:
+
----
oc apply -f endpoint-config.yaml
----

The ClusterController takes the following actions:

* The `EndpointConfig` creation starts `Reconcile()` in https://github.com/open-cluster-management/rcm-controller/blob/master/pkg/controller/endpointconfig/endpointconfig_controller.go[/pkg/controllers/endpointconfig/endpointconfig_controller.go].
* The controller uses information in `EndpointConfig` to generate a secret named `+${CLUSTER_NAME}-import+`.
* The `+${CLUSTER_NAME}-import+` secret contains the `import.yaml` that the user applies to a managed cluster to install `multicluster-endpoint`.

[#importing-the-multicluster-endpoint]
== Importing the multicluster-endpoint

. Obtain the `endpoint-crd.yaml` that was generated by the cluster controller.
+
Run the following command:
+
[source,bash]
----
kubectl get secret ${CLUSTER_NAME}-import -n ${CLUSTER_NAME} -o jsonpath={.data.endpoint-crd\\.yaml} | base64 --decode > endpoint-crd.yaml
----

. Obtain the `import.yaml` that was generated by the cluster controller.
Run the following command:
+
[source,bash]
----
kubectl get secret ${CLUSTER_NAME}-import -n ${CLUSTER_NAME} -o jsonpath={.data.import\\.yaml} | base64 --decode > import.yaml
----

. Log in to your target _managed_ cluster.
. Apply the `endpoint-crd.yaml` that was generated in step 1.
Run the following command:
+
----
kubectl apply -f endpoint-crd.yaml
----

. Apply the `import.yaml` file that was generated in step 2.
Run the following command:
+
----
kubectl apply -f import.yaml
----

. Validate the pod status on the target managed cluster.
Run the following command:
+
----
kubectl get pod -n multicluster-endpoint
----

. Validate `Ready` status for your imported cluster.
Run the following command from the _hub_ cluster:
+
----
kubectl get cluster -n ${CLUSTER_NAME}
----
