[#managing-observability]
= Managing observability

Review the following sections to learn more about customizing, managing, and viewing data collected by the observability service.

Collect logs about new information that is created for observability resources with the `must-gather` command. For more information, see the _Must-gather_ section in the link:../troubleshooting/troubleshooting_intro.adoc[Troubleshooting documentation].

* <<configuring-prometheus-rules,Configuring Prometheus rules>>
* <<creating-alertmanager-integrations,Creating AlertManager integrations>>
* <<viewing-and-exploring-data,Viewing and exploring data>>
* <<disable-observability,Disable observability>>

[#creating-rules]
== Configuring Prometheus rules

You can customize the observability resource by configuring Prometheus rules. For more information, see https://prometheus.io/docs/prometheus/latest/configuration/configuration/[Prometheus configuration]. 

Create two types of rules with Promethus to customize the `multicluster-observability-operator`, recording rules and alerting rules. 

Define recording rules to help to precompute queries. Define alerting rules to create alert conditions, and send notifications to an external service.

Complete the following steps to create recording rules: 

. Log in to your {product-title-short} hub cluster.
. 
By default, the alert rules are defined in the `thanos-rule-default-rules` configuration map in the `open-cluster-management-observability` namespace. You can create multple rules in the configuration.

For example, you can create an alert rule that notifies you when your CPU usage passes your defined value: 

----
data:
  custom_rules.yaml: |
    groups:
      - name: cluster-health
        rules:
        - alert: ClusterCPUHealth-jb
          annotations:
            summary: Notify when CPU utiliazation on a cluster is greater than the defined utilization limit
            description: "The cluster has a high CPU usage: {{ $value }} core for {{ $labels.cluster }} {{ $labels.clusterID }}."
         expr: |
           max(cluster:cpu_usage_cores:sum) by (clusterID, cluster, prometheus) > 0
         for: 5s
         labels:
           cluster: "{{ $labels.cluster }}"
           prometheus: "{{ $labels.prometheus }}"
           severity: critical
----
[#configuring-receiver-rules]
=== Configuring receiver rules

You can integrate external tools by configuring the receiver rules. Complete the following steps to update the receiver rules:

. Log in to your {ocp} hub cluster. 


[#viewing-and-exploring-data]
== Viewing and exploring data

View the data from your managed clusters by accessing Grafana. Complete the following steps to view the Grafana dashbord from the console:

. Log in to your {product-title-short} hub cluster. 
. From the navigation menu, select *Observe environments* > *Overview* > *Grafana link*
. You can access the Grafana dashboard from the _Clusters_ page. From the navigation menu, select *Automate infrastructure* > *Clusters* > *Grafana link*.
. Access the Prometheus metric explorer by selecting the *Explore* icon from the Grafana navigation menu.
. View the status of the `observability-addon`

[#disable-observability]
== Disable observability 

Disable the observability service to stop data from being collected and sent to the observability service on the {product-title-short} hub cluster. 

Update the `multicluster-observability-operator` resource by setting `enableMetrics` to `false`. Your updated resource might resemble the following change:

----
spec:
  availabilityConfig: High # Available values are High or Basic
  imagePullPolicy: Always
  imagePullSecret: multiclusterhub-operator-pull-secret
  observabilityAddonSpec: # The ObservabilityAddonSpec defines the global settings for all managed clusters which have observability add-on enabled
    enableMetrics: false #indicates the observability addon push metrics to hub server
----

When you disable observability, the `multicluster-observability-operator` continues to run on the managed cluster, while the `metrics-collector` deployment is scaledd to zero. When a managed cluster with the observability component is detached, the `metrics-collector` deployments are removed.

For more information on monitoring data from the console with the observability service, see xref:../observability/observe_intro.adoc#observing-environments[Observing environments].

